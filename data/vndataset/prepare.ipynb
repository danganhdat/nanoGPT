{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cccaa0f-2d0a-40b7-b502-55e85aacc712",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b622729-f740-433e-a430-c48be97ea7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download, HfApi\n",
    "from huggingface_hub import login\n",
    "import numpy as np\n",
    "import gzip\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de5c19f0-5036-4b55-b941-b760842960e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "login(token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b342964-0c99-41ca-b218-5843bb92c485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "downloaded_val_path = hf_hub_download(repo_id=\"danganhdat/bins\", filename=\"val_5M_tokens.bin\", repo_type=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95afd1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ba28677d07484a953ef76388030494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_10B_tokens.bin.gz:   0%|          | 0.00/10.8G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compressed_train_path = hf_hub_download(repo_id=\"danganhdat/bins\", filename=\"train_10B_tokens.bin.gz\", repo_type=\"dataset\")\n",
    "# ~7m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "095f4b4d-66de-43bf-9271-30230fbab0b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_path = \"./val_5M_tokens.bin\"\n",
    "\n",
    "with open(downloaded_val_path, \"rb\") as f_src:\n",
    "    with open(val_path, \"wb\") as f_dst:\n",
    "        shutil.copyfileobj(f_src, f_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a87ddcd6-5e41-4106-9a43-1ce295960b79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = \"./train_10B_tokens.bin\"\n",
    "\n",
    "# Read the compressed file\n",
    "with gzip.open(compressed_train_path, \"rb\") as f_in:\n",
    "    with open(train_path, \"wb\") as f_out:\n",
    "        f_out.write(f_in.read())\n",
    "        \n",
    "# ~2m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32c63d60-0e06-47af-ac8b-9018a0c809bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 4_834_912\n",
      "[15747   647  1674   778    39  1438  1099  1744   316   589   664  2303\n",
      "  1407   705   711 16525    17 11646  4513    11   384    47  2483  6703\n",
      "   198   198    47  8945  7188  1171   702   750   220  6767  2693  2060\n",
      "   384    47  2483  6703  6524  1477  3016  1099  1318   702   750    25\n",
      "   220     6 15456   628     6    26   220     6    33   388  1448   628\n",
      "  1942   892  1337     6   316   589   664  1271 16524    20    14    24\n",
      "    14    17    15    17    17  2303  1686  1407   705 16525    17 11646\n",
      "  4513  1760  6258 11646  4513    11 11523   534   430  6706    11   384\n",
      "    47  2483  6703     8    13   198   198   604   263  1062  1477  3016\n",
      "  1099  1318  1796   511  1448   717  1674  1936  2023  4652   973 17577\n",
      "  1096   778    39    11  1546  1078  6480  1114    11   624 15504 16525\n",
      "    24    35    16    12    24    21    23    13    15    18   625   705\n",
      "  6692    25  3055    43    39    41    37    19    17    17    18    37\n",
      "    56    15    20    21    17    20    22    11   705  1179  9796    37\n",
      "    19    17    36    12    16    15    20    21    17    20    21    13\n",
      "   198   498   470  1066  1099   581  1129  1477  3016    11 11733  7188\n",
      "  1171   702   750   220  6767  2693  2060   384    47  2483  6703  1133\n",
      "  1086  1615   870   647  1669   965   955   892  1195  1674  1936  2023\n",
      "  4652   973 17577  1096   778    39   625  1048  1576   435  2107  1279\n",
      "  3420   534   439   220    18 11733  7188  1171   702   750  1760 11657\n",
      "  1002    25   778   283   220    22   572   457  2962    11]\n"
     ]
    }
   ],
   "source": [
    "v = np.memmap(val_path, dtype=np.uint16, mode='r')\n",
    "print(f\"Length: {len(v):_}\")\n",
    "print(v[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13931801-3007-4a6e-9265-e7a6a4a5ce8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 10_046_904_843\n",
      "[   34  3890  1239  1427   980  3445  3157  2268  1723   718   778    12\n",
      "   728  2238    87   844  1398  3255   750  6498  4312   288  5488  4288\n",
      "  1637  1279   750  6230  1076  1195  3157   567  2140  1498  1358  2234\n",
      "  3157  5593  5319 16570  2040  1148  1873  2472  2234   717  5347  1714\n",
      "  2618  5725   876    13   778   332  6230  1076   435  2792  2617   876\n",
      "  3445  3157 19133   942   573  1041  1527  3089  1279  3157  2810  1416\n",
      " 16570  2040   625  1312   934  1760  4919 16524    15    15   684 12372\n",
      "   220     8    13 14002  1416 19133   942   573  1293  3615  2633   870\n",
      "  9164  3525 16524    15    15     4   709  1797  1195   832  1691  2002\n",
      "   649   586   844  1445  1178  1195  3157   567  2140  1498  1746   570\n",
      "    12   796    13 19957  2117  1751  1477   922   220    24    22    15\n",
      "    13    15    15    15 13361  1214  2060  1791  1438  1411 16525    15\n",
      "    16    24   198   198    51   364  1563  1477   922  1214  1195  4186\n",
      "  1751  6524  1784  3090  1279  3498 16524  5908 13361    14  1470  1437\n",
      "  5653  1907  2405  1407  2028   675  3255   692   948  1030   586  1398\n",
      "  6240  6604  4286    13   198   198 18861   220    22    14    16    17\n",
      "  2303  5329  1214   898  1029  6703 14189    11   384   592   581  3390\n",
      " 18475   765  1214  4186  1751  1760 15787    44     8  1575  1666  1478\n",
      "  3322 13361  1214  1771   220    24    15    15    13    15    15    15\n",
      "  1438  1411 16525    15    16    24    13   902   396  1030   586  4186\n",
      "  1751  3615  1394  1330  3351  1411  3018  2234  3090 16524]\n"
     ]
    }
   ],
   "source": [
    "t = np.memmap(train_path, dtype=np.uint16, mode='r')\n",
    "print(f\"Length: {len(t):_}\")\n",
    "print(t[:250])\n",
    "# 9_903_287_246"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf7f2824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dfbe41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1]  # 2nd input token is the query\n",
    "\n",
    "attn_scores_2 = torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attn_scores_2[i] = torch.dot(x_i, query) # dot product (transpose not necessary here since they are 1-dim vectors)\n",
    "\n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ba9abd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      "Sum: tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()\n",
    "\n",
    "print(\"Attention weights:\", attn_weights_2_tmp)\n",
    "print(\"Sum:\", attn_weights_2_tmp.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cb37d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "def softmax_naive(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
    "\n",
    "attn_weights_2_naive = softmax_naive(attn_scores_2)\n",
    "\n",
    "print(\"Attention weights:\", attn_weights_2_naive)\n",
    "print(\"Sum:\", attn_weights_2_naive.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1041ebfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
    "\n",
    "print(\"Attention weights:\", attn_weights_2)\n",
    "print(\"Sum:\", attn_weights_2.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e23ac4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4300, 0.5500, 0.5700, 0.2200, 0.7700, 0.0500],\n",
       "        [0.1500, 0.8700, 0.8500, 0.5800, 0.2500, 0.8000],\n",
       "        [0.8900, 0.6600, 0.6400, 0.3300, 0.1000, 0.5500]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.T"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
